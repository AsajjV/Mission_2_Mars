{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this assignment, you will build a web application that scrapes various websites for data related to the Mission to Mars and displays the information in a single HTML page. The following outlines what you need to do.\n",
    "\n",
    "\n",
    "Step 1 - Scraping\n",
    "\n",
    "Complete your initial scraping using Jupyter Notebook, BeautifulSoup, Pandas, and Requests/Splinter.\n",
    "\n",
    "\n",
    "Create a Jupyter Notebook file called mission_to_mars.ipynb and use this to complete all of your scraping and analysis tasks. The following outlines what you need to scrape."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dependencies\n",
    "from bs4 import BeautifulSoup as bs\n",
    "from splinter import Browser\n",
    "from splinter.exceptions import ElementDoesNotExist\n",
    "import requests\n",
    "import pymongo\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "executable_path = {'executable_path': 'chromedriver.exe'}\n",
    "browser = Browser('chrome', **executable_path, headless=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NASA Mars News\n",
    "\n",
    "\n",
    "Scrape the NASA Mars News Site and collect the latest News Title and Paragraph Text. Assign the text to variables that you can reference later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://mars.nasa.gov/news/\"\n",
    "response = requests.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "soup = bs(response.text,'html.parser')\n",
    "#print(soup.prettify())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NASA's Opportunity Rover Mission on Mars Comes to End\n",
      "NASA's Opportunity Mars rover mission is complete after 15 years on Mars. Opportunity's record-breaking exploration laid the groundwork for future missions to the Red Planet.\n"
     ]
    }
   ],
   "source": [
    "#Scrape the NASA Mars News Site and collect the latest News Title and Paragraph Text. \n",
    "#Assign the text to variables that you can reference later.\n",
    "\n",
    "#scrape title from latest news\n",
    "latest_title = soup.find(\"div\", class_=\"content_title\").text.strip()\n",
    "print(latest_title)\n",
    "#scrape teaser from latest news\n",
    "latest_teaser = soup.find(\"div\", class_=\"rollover_description\").text.strip()\n",
    "print(latest_teaser)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#JPL Mars Space Images - Featured Image\n",
    "\n",
    "#Visit the url for JPL Featured Space Image here.\n",
    "#Use splinter to navigate the site and find the image url for the current Featured Mars Image \n",
    "#and assign the url string to a variable called featured_image_url.\n",
    "#Make sure to find the image url to the full size .jpg image.\n",
    "#Make sure to save a complete url string for this image.\n",
    "\n",
    "JPL_url = \"https://www.jpl.nasa.gov/spaceimages/?search=&category=Mars\"\n",
    "browser.visit(JPL_url)\n",
    "html = browser.html\n",
    "JPL_soup = bs(html, \"html.parser\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/spaceimages/images/wallpaper/PIA23047-640x350.jpg\n",
      "https://www.jpl.nasa.gov/spaceimages/images/wallpaper/PIA23047-640x350.jpg\n"
     ]
    }
   ],
   "source": [
    "img = JPL_soup.find(\"div\", class_=\"image_and_description_container\").\\\n",
    "    find(\"div\", class_=\"img\").find(\"img\", class_=\"thumb\")\n",
    "mars_img = img.attrs['src']\n",
    "img_url = print(str(mars_img))\n",
    "mars_img\n",
    "\n",
    "featured_image_url = \"https://www.jpl.nasa.gov\" + mars_img\n",
    "print(featured_image_url)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visit the Mars Weather twitter account here and #scrape the latest Mars weather tweet from the page. \n",
    "#Save the tweet text for the weather report as a variable called mars_weather.\n",
    "\n",
    "tweet_url = \"https://twitter.com/marswxreport?lang=en\"\n",
    "tweet_resp = requests.get(tweet_url)\n",
    "tweet_soup = bs(tweet_resp.text, \"lxml\")\n",
    "tweet_weather = tweet_soup.find(\"p\", class_=\"TweetTextSize TweetTextSize--normal js-tweet-text tweet-text\").text\n",
    "tweet_weather"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Mars Facts\n",
    "\n",
    "#Visit the Mars Facts webpage here and use Pandas to scrape the table containing facts about the planet including Diameter, Mass, etc.\n",
    "\n",
    "facts_url = \"https://space-facts.com/mars/\"\n",
    "mars_tables = pd.read_html(facts_url)\n",
    "mars_df = mars_tables[0]\n",
    "mars_df.columns = [\"Description\", \"Value\"]\n",
    "mars_df.set_index(\"Description\",inplace=True)\n",
    "mars_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Use Pandas to convert the data to a HTML table string.\n",
    "mars_df_html = mars_df.to_html()\n",
    "mars_df_html = mars_df_html.replace('\\n','')\n",
    "mars_df_html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Mars Hemispheres\n",
    "\n",
    "#Visit the USGS Astrogeology site here to obtain high resolution images for each of Mar's hemispheres.\n",
    "USGS_url = \"https://astrogeology.usgs.gov/search/results?q=hemisphere+enhanced&k1=target&v1=Mars\"\n",
    "browser.visit(USGS_url)\n",
    "html = browser.html\n",
    "USGS_soup = bs(html, \"html.parser\")\n",
    "print(USGS_soup.prettify())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#You will need to click each of the links to the hemispheres in order to find the image url to the full resolution image.\n",
    "#Save both the image url string for the full resolution hemisphere image, \n",
    "#and the Hemisphere title containing the hemisphere name. \n",
    "#Use a Python dictionary to store the data using the keys img_url and title.\n",
    "#Append the dictionary with the image url string and the hemisphere title to a list. \n",
    "#This list will contain one dictionary for each hemisphere.\n",
    "\n",
    "products = USGS_soup.find(\"div\", class_=\"collapsible results\")\n",
    "hemispheres = products.find_all(\"h3\")\n",
    "hemispheres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make lists to add urls and titles to:\n",
    "#img_url = []\n",
    "#title = []\n",
    "dict_list = []\n",
    "\n",
    "#for loop - add info to lists\n",
    "for hemisphere in hemispheres:\n",
    "    hemisphere_dict = {}\n",
    "    try:\n",
    "        title = (hemisphere.text)\n",
    "        hemisphere_dict['title'] = title\n",
    "        #click the link, pull in the href for the image\n",
    "        browser.click_link_by_partial_text(\"Enhanced\")\n",
    "        samples = browser.find_link_by_text(\"Sample\").first\n",
    "        link=samples[\"href\"]\n",
    "        hemisphere_dict[\"img_url\"] = link\n",
    "        dict_list.append(hemisphere_dict)\n",
    "    except ElementDoesNotExist:\n",
    "            print(\"Out of appendable junk\")\n",
    "    \n",
    "\n",
    "dict_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
